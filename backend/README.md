# RAG Backend with Django

A production-ready RAG (Retrieval Augmented Generation) backend built with Django, featuring JWT authentication, Cloudinary storage, OCR + Vision processing, chat history, and streaming responses.

## Features

- ğŸ” **JWT Authentication** - Secure email-based auth with access/refresh tokens
- â˜ï¸ **Cloudinary Storage** - No local file storage, everything on cloud
- ğŸ“„ **Multi-format Support** - PDF, DOCX, PNG, JPG, JPEG
- ğŸ–¼ï¸ **Smart Image Processing** - OCR with conditional AI Vision
- ğŸ’¬ **Chat History** - Persistent sessions and messages
- ğŸ“š **Source Tracking** - Know which documents were used in responses
- ğŸŒŠ **Streaming Responses** - Real-time token streaming with SSE
- ğŸ”’ **User Isolation** - Users can only access their own data

---

## How It Works

### ğŸ“¤ Document Upload Pipeline

```
User uploads file
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Upload to Cloudinary (no local storage)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Detect file type                            â”‚
â”‚     â”œâ”€ PDF/DOCX â†’ Text extraction               â”‚
â”‚     â””â”€ Image â†’ OCR + Vision pipeline            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Chunk text (500 chars, 50 overlap)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Generate embeddings (all-MiniLM-L6-v2)      â”‚
â”‚     384-dimensional vectors                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. Store in PostgreSQL + pgvector              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ğŸ–¼ï¸ Image Processing (OCR + Vision)

When you upload an image, the system intelligently decides whether to use just OCR or also call the Vision API:

```
Image uploaded
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Resize if > 2000px (prevent timeout)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Run Tesseract OCR                           â”‚
â”‚     Extract text + compute quality signals:     â”‚
â”‚     â€¢ confidence (avg OCR confidence)           â”‚
â”‚     â€¢ text_coverage (% of image with text)      â”‚
â”‚     â€¢ box_density (text boxes per area)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Check if Vision API needed                  â”‚
â”‚     TRIGGERS if ANY of:                         â”‚
â”‚     â€¢ text_coverage < 0.1 (sparse text)         â”‚
â”‚     â€¢ box_density < 0.05 (few text regions)     â”‚
â”‚     â€¢ confidence < 50 (low OCR quality)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€ NO â†’ Use OCR text only
       â”‚
       â””â”€â”€â”€ YES â”€â”€â”€â–¶ Call GPT-4o-mini Vision API
                           â”‚
                           â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ "Describe this image    â”‚
                    â”‚  concisely for search"  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                    Merge: Vision description + OCR text
```

**Example:**
- ğŸ“„ Scanned document with clear text â†’ OCR only (fast, cheap)
- ğŸï¸ Photo with minimal text â†’ Vision API called (gets AI description)
- ğŸ“Š Chart/diagram â†’ Vision API called (describes visual content)

---

### ğŸ’¬ Chat Query Classification

When a user sends a message, the system first classifies the query to decide whether to retrieve documents:

```
User message received
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Query Classifier (LLM-based)                   â”‚
â”‚                                                 â”‚
â”‚  Classifies into one of:                        â”‚
â”‚  â€¢ DOCUMENT_QUERY - needs user's documents      â”‚
â”‚  â€¢ GENERAL_KNOWLEDGE - can answer directly      â”‚
â”‚  â€¢ GREETING - simple greeting/chitchat          â”‚
â”‚  â€¢ CLARIFICATION - needs more info from user    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
   Needs retrieval?
       â”‚
       â”œâ”€â”€â”€ NO (greeting/general) â”€â”€â”€â–¶ Answer directly
       â”‚
       â””â”€â”€â”€ YES (document query) â”€â”€â”€â–¶ Retrieve context
```

**Examples:**
| Query | Classification | Retrieves Docs? |
|-------|---------------|-----------------|
| "Hello!" | GREETING | âŒ No |
| "What is Python?" | GENERAL_KNOWLEDGE | âŒ No |
| "What's in my documents?" | DOCUMENT_QUERY | âœ… Yes |
| "Summarize my uploaded PDF" | DOCUMENT_QUERY | âœ… Yes |

---

### ğŸ” RAG Pipeline (Retrieval + Generation)

When documents need to be retrieved:

```
Query classified as DOCUMENT_QUERY
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. EMBED the query                             â”‚
â”‚     Same model: all-MiniLM-L6-v2                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. VECTOR SEARCH (pgvector)                    â”‚
â”‚     â€¢ Cosine similarity search                  â”‚
â”‚     â€¢ Filter by user_id (isolation)             â”‚
â”‚     â€¢ Return top-k chunks (default: 8)          â”‚
â”‚     â€¢ Threshold: similarity > 0.25              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. CHECK relevance                             â”‚
â”‚     If no chunks above threshold:               â”‚
â”‚     â†’ used_context = false                      â”‚
â”‚     â†’ Answer without documents                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. FORMAT context                              â”‚
â”‚     Combine top chunks into prompt:             â”‚
â”‚     "Based on these documents: {chunks}"        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. GENERATE answer (GPT-4)                     â”‚
â”‚     System prompt + context + question          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. EXTRACT sources                             â”‚
â”‚     Top 3 chunks â†’ asset_id + excerpt           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
Return: { answer, used_context, sources, session_id }
```

---

### ğŸ“Š Response Structure

```json
{
  "session_id": "abc123...",
  "answer": "Based on your documents...",
  "used_context": true,
  "sources": [
    {
      "asset_id": "0fb6115c-eaad...",
      "excerpt": "First 100 chars of the relevant chunk..."
    }
  ]
}
```

| Field | Description |
|-------|-------------|
| `session_id` | Unique conversation ID (use to continue chat) |
| `answer` | AI-generated response |
| `used_context` | `true` if your documents were used |
| `sources` | Which documents contributed (when used_context=true) |

---

### ğŸ—‘ï¸ Asset Deletion (Cascade)

When you delete an asset, everything is cleaned up:

```
DELETE /api/assets/{id}
       â”‚
       â”œâ”€â†’ Delete from Cloudinary â˜ï¸
       â”‚
       â””â”€â†’ Delete Asset from database
            â”‚
            â””â”€â†’ CASCADE: All DocumentChunks deleted
                 (embeddings removed from pgvector)
```

---

### ğŸ” User Isolation

Every query is scoped to the authenticated user:

- **Uploads**: `asset.user = request.user`
- **Retrieval**: `WHERE user_id = current_user.id`
- **Chat sessions**: `session.user = request.user`
- **Asset list**: `Asset.objects.filter(user=request.user)`

Users can **never** see or query other users' data.

## Quick Start

### Prerequisites

- Python 3.12+
- PostgreSQL with pgvector extension (or Neon)
- Tesseract OCR
- Cloudinary account (free tier works)
- OpenAI API key

### Install Tesseract OCR

```bash
# Ubuntu/Debian
sudo apt install tesseract-ocr

# macOS
brew install tesseract

# Windows
# Download from: https://github.com/UB-Mannheim/tesseract/wiki
```

---

## Installation

### Option 1: Using UV (Recommended) âš¡

[UV](https://github.com/astral-sh/uv) is a fast Python package manager. This is the recommended way.

```bash
# Install uv (if not installed)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Clone the repo
git clone <your-repo-url>
cd backend

# Create virtual environment and install dependencies
uv sync

# Copy environment file
cp .env.example .env

# Edit .env with your credentials
nano .env

# Run migrations
uv run python manage.py migrate

# Create superuser (for admin panel)
uv run python manage.py createsuperuser

# Start server
uv run uvicorn config.asgi:application --reload --port 8000
```

### Option 2: Using pip + requirements.txt

```bash
# Clone the repo
git clone <your-repo-url>
cd backend

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
# OR
.venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Copy environment file
cp .env.example .env

# Edit .env with your credentials
nano .env

# Run migrations
python manage.py migrate

# Create superuser (for admin panel)
python manage.py createsuperuser

# Start server
uvicorn config.asgi:application --reload --port 8000
```

---

## Environment Variables

Create a `.env` file in the backend folder:

```env
# Django
SECRET_KEY=your-super-secret-key-here
DEBUG=True

# Database (PostgreSQL with pgvector)
DATABASE_URL=postgresql://user:password@host:5432/dbname?sslmode=require

# OpenAI
OPENAI_API_KEY=sk-your-openai-api-key

# Cloudinary (get from cloudinary.com dashboard)
CLOUDINARY_CLOUD_NAME=your-cloud-name
CLOUDINARY_API_KEY=your-api-key
CLOUDINARY_API_SECRET=your-api-secret

# JWT Token Lifetimes (optional)
JWT_ACCESS_HOURS=1
JWT_REFRESH_DAYS=7

# OCR Thresholds (optional - defaults work well)
OCR_TEXT_COVERAGE_THRESHOLD=0.1
OCR_BOX_DENSITY_THRESHOLD=0.05
OCR_CONFIDENCE_THRESHOLD=50
```

---

## API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/auth/register` | Register new user |
| POST | `/api/auth/login` | Login, get tokens |
| POST | `/api/auth/refresh` | Refresh access token |
| POST | `/api/documents/upload` | Upload PDF/DOCX/Image |
| GET | `/api/assets` | List user's assets |
| DELETE | `/api/assets/{id}` | Delete asset |
| POST | `/api/chat` | Chat (non-streaming) |
| POST | `/api/chat/stream` | Chat (streaming SSE) |
| GET | `/api/chat/sessions` | List chat sessions |
| GET | `/api/chat/sessions/{id}` | Get session messages |

ğŸ“– **Full API documentation:** See `API_DOCUMENTATION.md`

---

## Usage Examples

### Register and Login

```bash
# Register
curl -X POST http://localhost:8000/api/auth/register \
  -H "Content-Type: application/json" \
  -d '{"email": "user@example.com", "password": "pass123", "confirm_password": "pass123"}'

# Login
curl -X POST http://localhost:8000/api/auth/login \
  -H "Content-Type: application/json" \
  -d '{"email": "user@example.com", "password": "pass123"}'
```

### Upload a Document

```bash
curl -X POST http://localhost:8000/api/documents/upload \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN" \
  -F "file=@document.pdf"
```

### Chat

```bash
curl -X POST http://localhost:8000/api/chat \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"message": "What is in my documents?"}'
```

---

## Admin Panel

Access the Django admin at: `http://localhost:8000/admin`

Login with your superuser credentials to:
- View/manage users
- Browse uploaded assets (with image previews)
- Inspect document chunks
- View chat sessions and messages

---

## Project Structure

```
backend/
â”œâ”€â”€ accounts/           # User authentication
â”‚   â”œâ”€â”€ models.py      # Custom User model
â”‚   â”œâ”€â”€ views.py       # Register view
â”‚   â””â”€â”€ serializers.py
â”œâ”€â”€ rag/               # RAG functionality
â”‚   â”œâ”€â”€ models.py      # Asset, DocumentChunk, ChatSession, ChatMessage
â”‚   â”œâ”€â”€ views.py       # All API views
â”‚   â”œâ”€â”€ serializers.py
â”‚   â”œâ”€â”€ admin.py       # Admin configuration
â”‚   â”œâ”€â”€ pipeline/      # RAG pipeline
â”‚   â”‚   â”œâ”€â”€ retriever.py
â”‚   â”‚   â”œâ”€â”€ generator.py
â”‚   â”‚   â””â”€â”€ query_classifier.py
â”‚   â””â”€â”€ services/      # External services
â”‚       â”œâ”€â”€ llm.py            # OpenAI integration
â”‚       â”œâ”€â”€ embeddings.py     # Sentence transformers
â”‚       â”œâ”€â”€ cloudinary_service.py
â”‚       â”œâ”€â”€ ocr_service.py    # Tesseract OCR
â”‚       â”œâ”€â”€ vision_service.py # GPT-4 Vision
â”‚       â””â”€â”€ image_processor.py
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ settings.py
â”‚   â”œâ”€â”€ urls.py
â”‚   â””â”€â”€ asgi.py
â”œâ”€â”€ .env.example
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
â””â”€â”€ API_DOCUMENTATION.md
```

---

## Development

### Database Migrations

```bash
# Using uv
uv run python manage.py makemigrations
uv run python manage.py migrate

# Using pip
python manage.py makemigrations
python manage.py migrate
```

### Collect Static Files (for production)

```bash
# Using uv
uv run python manage.py collectstatic --noinput

# Using pip
python manage.py collectstatic --noinput
```

---

## Deployment

### Environment Variables for Production

```env
DEBUG=False
SECRET_KEY=<generate-a-strong-key>
ALLOWED_HOSTS=your-domain.com
CORS_ALLOWED_ORIGINS=https://your-frontend.com
```

### Recommended Platforms

- **Railway** - Easy Django deployment
- **Render** - Free tier available
- **Fly.io** - Global edge deployment
- **AWS/GCP** - Enterprise scale

---

## Tech Stack

- **Framework:** Django 5.1 + Django REST Framework
- **Async:** ADRF (Async Django REST Framework)
- **Database:** PostgreSQL with pgvector
- **Auth:** djangorestframework-simplejwt
- **Storage:** Cloudinary
- **AI:** OpenAI GPT-4
- **Embeddings:** sentence-transformers (all-MiniLM-L6-v2)
- **OCR:** Tesseract
- **Server:** Uvicorn (ASGI)

---

## License

MIT

---

## Contributing

PRs welcome! Please ensure all tests pass before submitting.
